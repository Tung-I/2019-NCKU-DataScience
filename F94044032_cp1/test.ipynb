{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# iris.data = [(Sepal Length, Sepal Width, Petal Length, Petal Width)]\n",
    "# 加载iris数据集，抽取花萼长度和花瓣宽度，分割每类的x_vals值和y_vals值\n",
    "iris = datasets.load_iris()\n",
    "x_vals = np.array([[x[0], x[3]] for x in iris.data])\n",
    "y_vals = np.array([1 if y==0 else -1 for y in iris.target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "# Declare batch size\n",
    "# 声明批量大小（偏向于更大批量大小）\n",
    "batch_size = 150\n",
    "lr_rate = 0.01\n",
    "gamma_val = -25.0\n",
    " \n",
    "# Initialize placeholders\n",
    "x_data = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "prediction_grid = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    " \n",
    "# Create variables for svm\n",
    "b = tf.Variable(tf.random_normal(shape=[1,batch_size]))\n",
    " \n",
    "# Gaussian (RBF) kernel\n",
    "# 声明批量大小（偏向于更大批量大小）\n",
    "gamma = tf.constant(gamma_val)\n",
    "sq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\n",
    "my_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n",
    " \n",
    "# Compute SVM Model\n",
    "first_term = tf.reduce_sum(b)\n",
    "b_vec_cross = tf.matmul(tf.transpose(b), b)\n",
    "y_target_cross = tf.matmul(y_target, tf.transpose(y_target))\n",
    "second_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)))\n",
    "loss = tf.negative(tf.subtract(first_term, second_term))\n",
    " \n",
    "# Gaussian (RBF) prediction kernel\n",
    "# 创建一个预测核函数\n",
    "rA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1),[-1,1])\n",
    "rB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1),[-1,1])\n",
    "pred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\n",
    "pred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n",
    " \n",
    "# 声明一个准确度函数，其为正确分类的数据点的百分比\n",
    "prediction_output = tf.matmul(tf.multiply(tf.transpose(y_target),b), pred_kernel)\n",
    "prediction = tf.sign(prediction_output-tf.reduce_mean(prediction_output))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(y_target)), tf.float32))\n",
    " \n",
    "# Declare optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(lr_rate)\n",
    "train_step = my_opt.minimize(loss)\n",
    " \n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    " \n",
    "# Training loop\n",
    "loss_vec = []\n",
    "batch_accuracy = []\n",
    "for i in range(300):\n",
    "    rand_index = np.random.choice(len(x_vals), size=batch_size)\n",
    "    rand_x = x_vals[rand_index]\n",
    "    rand_y = np.transpose([y_vals[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    " \n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    loss_vec.append(temp_loss)\n",
    " \n",
    "    acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n",
    "                       y_target: rand_y,\n",
    "                       prediction_grid:rand_x})\n",
    "    batch_accuracy.append(acc_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.56666666,\n",
       " 0.47333333,\n",
       " 0.6066667,\n",
       " 0.55333334,\n",
       " 0.6333333,\n",
       " 0.73333335,\n",
       " 0.58666664,\n",
       " 0.76,\n",
       " 0.48666668,\n",
       " 0.53333336,\n",
       " 0.7133333,\n",
       " 0.47333333,\n",
       " 0.5133333,\n",
       " 0.6066667,\n",
       " 0.75333333,\n",
       " 0.7733333,\n",
       " 0.7266667,\n",
       " 0.7,\n",
       " 0.52666664,\n",
       " 0.73333335,\n",
       " 0.6,\n",
       " 0.78,\n",
       " 0.79333335,\n",
       " 0.78,\n",
       " 0.68666667,\n",
       " 0.79333335,\n",
       " 0.91333336,\n",
       " 0.82666665,\n",
       " 0.68666667,\n",
       " 0.84,\n",
       " 0.68666667,\n",
       " 0.8666667,\n",
       " 0.9266667,\n",
       " 0.96,\n",
       " 0.85333335,\n",
       " 0.82666665,\n",
       " 0.8,\n",
       " 0.76,\n",
       " 0.7866667,\n",
       " 0.91333336,\n",
       " 0.92,\n",
       " 0.96666664,\n",
       " 0.78,\n",
       " 0.8466667,\n",
       " 0.8666667,\n",
       " 0.93333334,\n",
       " 0.91333336,\n",
       " 0.96,\n",
       " 0.9266667,\n",
       " 0.85333335,\n",
       " 0.88,\n",
       " 0.9266667,\n",
       " 0.9266667,\n",
       " 0.93333334,\n",
       " 0.97333336,\n",
       " 0.84,\n",
       " 0.97333336,\n",
       " 0.87333333,\n",
       " 0.98,\n",
       " 0.93333334,\n",
       " 0.8933333,\n",
       " 0.85333335,\n",
       " 0.9,\n",
       " 0.96666664,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 0.94666666,\n",
       " 0.92,\n",
       " 0.9066667,\n",
       " 0.96666664,\n",
       " 0.8933333,\n",
       " 0.96,\n",
       " 1.0,\n",
       " 0.96666664,\n",
       " 0.9866667,\n",
       " 0.9266667,\n",
       " 0.9533333,\n",
       " 0.94666666,\n",
       " 0.97333336,\n",
       " 0.99333334,\n",
       " 0.96,\n",
       " 0.98,\n",
       " 0.91333336,\n",
       " 0.9533333,\n",
       " 0.9266667,\n",
       " 0.98,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 0.9533333,\n",
       " 0.87333333,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 0.9866667,\n",
       " 0.99333334,\n",
       " 0.8466667,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 0.9866667,\n",
       " 0.96666664,\n",
       " 0.96,\n",
       " 0.99333334,\n",
       " 0.92,\n",
       " 0.99333334,\n",
       " 0.99333334,\n",
       " 0.9866667,\n",
       " 0.96,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.94,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.96666664,\n",
       " 0.96,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.96666664,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 0.9066667,\n",
       " 1.0,\n",
       " 0.8933333,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 0.98,\n",
       " 1.0,\n",
       " 0.94,\n",
       " 0.99333334,\n",
       " 0.98,\n",
       " 0.92,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 0.9866667,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.96666664,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.91333336,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 0.94666666,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.87333333,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 0.9066667,\n",
       " 0.96,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.94,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.9266667,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.92,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 0.93333334,\n",
       " 0.99333334,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.91333336,\n",
       " 0.99333334,\n",
       " 0.92,\n",
       " 0.92,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.9066667,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.94666666,\n",
       " 1.0,\n",
       " 0.98,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.94,\n",
       " 0.98,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 0.91333336,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.99333334,\n",
       " 0.94666666,\n",
       " 0.99333334,\n",
       " 0.98,\n",
       " 0.9533333,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 0.88666666,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.85333335,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.92,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 0.9533333,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 0.97333336,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9866667,\n",
       " 0.98,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 0.99333334,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.97333336,\n",
       " 0.9866667,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3025055,\n",
       " 0.8025087,\n",
       " -0.6974889,\n",
       " -2.1974893,\n",
       " -3.6974878,\n",
       " -5.1974883,\n",
       " -6.697483,\n",
       " -8.197483,\n",
       " -9.697484,\n",
       " -11.197483,\n",
       " -12.69748,\n",
       " -14.197481,\n",
       " -15.697478,\n",
       " -17.19748,\n",
       " -18.697477,\n",
       " -20.197474,\n",
       " -21.697477,\n",
       " -23.197474,\n",
       " -24.697472,\n",
       " -26.19747,\n",
       " -27.697474,\n",
       " -29.197472,\n",
       " -30.69747,\n",
       " -32.197464,\n",
       " -33.697468,\n",
       " -35.197468,\n",
       " -36.697464,\n",
       " -38.19746,\n",
       " -39.69746,\n",
       " -41.197464,\n",
       " -42.697456,\n",
       " -44.19746,\n",
       " -45.69746,\n",
       " -47.19746,\n",
       " -48.697456,\n",
       " -50.197453,\n",
       " -51.697453,\n",
       " -53.197453,\n",
       " -54.697453,\n",
       " -56.19745,\n",
       " -57.69745,\n",
       " -59.197453,\n",
       " -60.697453,\n",
       " -62.197445,\n",
       " -63.697445,\n",
       " -65.19745,\n",
       " -66.69745,\n",
       " -68.19744,\n",
       " -69.69744,\n",
       " -71.19744,\n",
       " -72.69744,\n",
       " -74.19745,\n",
       " -75.69743,\n",
       " -77.19744,\n",
       " -78.69744,\n",
       " -80.19744,\n",
       " -81.69743,\n",
       " -83.19743,\n",
       " -84.69743,\n",
       " -86.19743,\n",
       " -87.69743,\n",
       " -89.197426,\n",
       " -90.697426,\n",
       " -92.197426,\n",
       " -93.69743,\n",
       " -95.19742,\n",
       " -96.69742,\n",
       " -98.197426,\n",
       " -99.69742,\n",
       " -101.19741,\n",
       " -102.69742,\n",
       " -104.197426,\n",
       " -105.69742,\n",
       " -107.19742,\n",
       " -108.69741,\n",
       " -110.19741,\n",
       " -111.69741,\n",
       " -113.19741,\n",
       " -114.69741,\n",
       " -116.19742,\n",
       " -117.69741,\n",
       " -119.19741,\n",
       " -120.6974,\n",
       " -122.19741,\n",
       " -123.6974,\n",
       " -125.197395,\n",
       " -126.6974,\n",
       " -128.1974,\n",
       " -129.6974,\n",
       " -131.1974,\n",
       " -132.69739,\n",
       " -134.19739,\n",
       " -135.69739,\n",
       " -137.19739,\n",
       " -138.6974,\n",
       " -140.1974,\n",
       " -141.69739,\n",
       " -143.19739,\n",
       " -144.69739,\n",
       " -146.19739,\n",
       " -147.69739,\n",
       " -149.19739,\n",
       " -150.69739,\n",
       " -152.19739,\n",
       " -153.69737,\n",
       " -155.19737,\n",
       " -156.69739,\n",
       " -158.19739,\n",
       " -159.69737,\n",
       " -161.19737,\n",
       " -162.69737,\n",
       " -164.19737,\n",
       " -165.69737,\n",
       " -167.19737,\n",
       " -168.69739,\n",
       " -170.19737,\n",
       " -171.69736,\n",
       " -173.19736,\n",
       " -174.69737,\n",
       " -176.19737,\n",
       " -177.69737,\n",
       " -179.19737,\n",
       " -180.69737,\n",
       " -182.19737,\n",
       " -183.69737,\n",
       " -185.19739,\n",
       " -186.69737,\n",
       " -188.19736,\n",
       " -189.69736,\n",
       " -191.19736,\n",
       " -192.69736,\n",
       " -194.19736,\n",
       " -195.69736,\n",
       " -197.19737,\n",
       " -198.69736,\n",
       " -200.19734,\n",
       " -201.69734,\n",
       " -203.19734,\n",
       " -204.69736,\n",
       " -206.19736,\n",
       " -207.69736,\n",
       " -209.19736,\n",
       " -210.69734,\n",
       " -212.19733,\n",
       " -213.69734,\n",
       " -215.19736,\n",
       " -216.69736,\n",
       " -218.19734,\n",
       " -219.69734,\n",
       " -221.19734,\n",
       " -222.69733,\n",
       " -224.19733,\n",
       " -225.69734,\n",
       " -227.19734,\n",
       " -228.69733,\n",
       " -230.19733,\n",
       " -231.69733,\n",
       " -233.19734,\n",
       " -234.69734,\n",
       " -236.19731,\n",
       " -237.69733,\n",
       " -239.19733,\n",
       " -240.69733,\n",
       " -242.19734,\n",
       " -243.69733,\n",
       " -245.19733,\n",
       " -246.69733,\n",
       " -248.19731,\n",
       " -249.69731,\n",
       " -251.19733,\n",
       " -252.69733,\n",
       " -254.19731,\n",
       " -255.69731,\n",
       " -257.19733,\n",
       " -258.69733,\n",
       " -260.19733,\n",
       " -261.6973,\n",
       " -263.19733,\n",
       " -264.69733,\n",
       " -266.19733,\n",
       " -267.6973,\n",
       " -269.1973,\n",
       " -270.6973,\n",
       " -272.19733,\n",
       " -273.69733,\n",
       " -275.19733,\n",
       " -276.69733,\n",
       " -278.1973,\n",
       " -279.69733,\n",
       " -281.19733,\n",
       " -282.69733,\n",
       " -284.1973,\n",
       " -285.6973,\n",
       " -287.1973,\n",
       " -288.6973,\n",
       " -290.19733,\n",
       " -291.69733,\n",
       " -293.19733,\n",
       " -294.6973,\n",
       " -296.19733,\n",
       " -297.6973,\n",
       " -299.1973,\n",
       " -300.6973,\n",
       " -302.1973,\n",
       " -303.6973,\n",
       " -305.1973,\n",
       " -306.6973,\n",
       " -308.19733,\n",
       " -309.69733,\n",
       " -311.1973,\n",
       " -312.6973,\n",
       " -314.1973,\n",
       " -315.6973,\n",
       " -317.1973,\n",
       " -318.69727,\n",
       " -320.1973,\n",
       " -321.6973,\n",
       " -323.1973,\n",
       " -324.69733,\n",
       " -326.1973,\n",
       " -327.6973,\n",
       " -329.19733,\n",
       " -330.69733,\n",
       " -332.19733,\n",
       " -333.69733,\n",
       " -335.19727,\n",
       " -336.6973,\n",
       " -338.19727,\n",
       " -339.6973,\n",
       " -341.19727,\n",
       " -342.6973,\n",
       " -344.19733,\n",
       " -345.6973,\n",
       " -347.1973,\n",
       " -348.6973,\n",
       " -350.1973,\n",
       " -351.6973,\n",
       " -353.1973,\n",
       " -354.6973,\n",
       " -356.1973,\n",
       " -357.6973,\n",
       " -359.19733,\n",
       " -360.69733,\n",
       " -362.1973,\n",
       " -363.69733,\n",
       " -365.19733,\n",
       " -366.6973,\n",
       " -368.19733,\n",
       " -369.6973,\n",
       " -371.1973,\n",
       " -372.69733,\n",
       " -374.1973,\n",
       " -375.69727,\n",
       " -377.19736,\n",
       " -378.69733,\n",
       " -380.19733,\n",
       " -381.69733,\n",
       " -383.1973,\n",
       " -384.69733,\n",
       " -386.1973,\n",
       " -387.69733,\n",
       " -389.1973,\n",
       " -390.6973,\n",
       " -392.19733,\n",
       " -393.69733,\n",
       " -395.19733,\n",
       " -396.69733,\n",
       " -398.19733,\n",
       " -399.69733,\n",
       " -401.19733,\n",
       " -402.69733,\n",
       " -404.19733,\n",
       " -405.69733,\n",
       " -407.19733,\n",
       " -408.69733,\n",
       " -410.19733,\n",
       " -411.69736,\n",
       " -413.19736,\n",
       " -414.69736,\n",
       " -416.19736,\n",
       " -417.69736,\n",
       " -419.19736,\n",
       " -420.6974,\n",
       " -422.19736,\n",
       " -423.69736,\n",
       " -425.19736,\n",
       " -426.6974,\n",
       " -428.1974,\n",
       " -429.6974,\n",
       " -431.19742,\n",
       " -432.69742,\n",
       " -434.1974,\n",
       " -435.6974,\n",
       " -437.19742,\n",
       " -438.6974,\n",
       " -440.19742,\n",
       " -441.69742,\n",
       " -443.19745,\n",
       " -444.69748,\n",
       " -446.19745]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
